#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿ƒç†å­¦è¯æ¡HTMLæ–‡ä»¶ä¸­æ–‡å†…å®¹æå–è„šæœ¬
ä»5ä¸ªå¿ƒç†å­¦æ¦‚å¿µçš„HTMLæ–‡ä»¶ä¸­æå–æ‰€æœ‰ä¸­æ–‡æ–‡æœ¬å†…å®¹
"""

import os
import re
import glob
from bs4 import BeautifulSoup
from pathlib import Path

def is_chinese_char(char):
    """åˆ¤æ–­å­—ç¬¦æ˜¯å¦ä¸ºä¸­æ–‡å­—ç¬¦"""
    return '\u4e00' <= char <= '\u9fff'

def extract_chinese_text(text):
    """ä»æ–‡æœ¬ä¸­æå–åŒ…å«ä¸­æ–‡çš„å¥å­å’Œæ®µè½"""
    if not text:
        return ""
    
    # æ¸…ç†æ–‡æœ¬
    text = text.strip()
    if not text:
        return ""
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
    has_chinese = any(is_chinese_char(char) for char in text)
    if not has_chinese:
        return ""
    
    # è¿‡æ»¤æ‰çº¯æ ‡ç‚¹ç¬¦å·æˆ–è¿‡çŸ­çš„æ–‡æœ¬
    if len(text) < 2:
        return ""
    
    # è¿‡æ»¤æ‰å¸¸è§çš„æ— æ„ä¹‰æ–‡æœ¬
    skip_patterns = [
        r'^[\s\-_=\.\,\;\:\!\?\(\)\[\]]*$',  # çº¯ç¬¦å·
        r'^[0-9\s\-_=\.\,\;\:\!\?\(\)\[\]]*$',  # çº¯æ•°å­—å’Œç¬¦å·
        r'^[a-zA-Z\s\-_=\.\,\;\:\!\?\(\)\[\]]*$',  # çº¯è‹±æ–‡å’Œç¬¦å·
    ]
    
    for pattern in skip_patterns:
        if re.match(pattern, text):
            return ""
    
    return text

def extract_html_chinese_content(html_file_path):
    """ä»HTMLæ–‡ä»¶æå–ä¸­æ–‡å†…å®¹"""
    try:
        with open(html_file_path, 'r', encoding='utf-8') as file:
            content = file.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {html_file_path}: {e}")
        return []
    
    try:
        soup = BeautifulSoup(content, 'html.parser')
        
        # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
        for script in soup(["script", "style"]):
            script.decompose()
        
        # è·å–æ‰€æœ‰æ–‡æœ¬
        all_texts = []
        
        # æå–æ ‡é¢˜
        title = soup.find('title')
        if title:
            title_text = extract_chinese_text(title.get_text())
            if title_text:
                all_texts.append(f"ã€æ ‡é¢˜ã€‘{title_text}")
        
        # æå–ä¸»è¦å†…å®¹åŒºåŸŸçš„æ–‡æœ¬
        content_selectors = [
            '#mw-content-text',  # ç»´åŸºç™¾ç§‘ä¸»å†…å®¹
            '.mw-parser-output',  # ç»´åŸºç™¾ç§‘è§£æè¾“å‡º
            'body',  # å¤‡ç”¨ï¼šæ•´ä¸ªbody
        ]
        
        main_content = None
        for selector in content_selectors:
            main_content = soup.select_one(selector)
            if main_content:
                break
        
        if not main_content:
            main_content = soup
        
        # æå–æ®µè½æ–‡æœ¬
        for element in main_content.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li', 'td', 'th']):
            text = extract_chinese_text(element.get_text())
            if text and len(text) > 3:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                all_texts.append(text)
        
        return all_texts
        
    except Exception as e:
        print(f"âŒ è§£æHTMLå¤±è´¥ {html_file_path}: {e}")
        return []

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æå–5ä¸ªå¿ƒç†å­¦è¯æ¡çš„ä¸­æ–‡å†…å®¹...")
    
    # æŸ¥æ‰¾HTMLæ–‡ä»¶
    html_files = [
        "resource/DARVO - ç»´åŸºç™¾ç§‘ ---- Wikipedia (2025_9_21 18ï¼š07ï¼š57).html",
        "resource/ä¹ å¾—æ€§å¤±åŠ© - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦ (2025_9_21 18ï¼š00ï¼š32).html", 
        "resource/åˆ›ä¼¤æ€§ç»“åˆ - ç»´åŸºç™¾ç§‘ --- Traumatic bonding - Wikipedia (2025_9_21 18ï¼š06ï¼š55).html",
        "resource/ç…¤æ°”ç¯æ•ˆåº” - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦ (2025_9_21 18ï¼š07ï¼š39).html",
        "resource/çˆ±æƒ…è½°ç‚¸ - ç»´åŸºç™¾ç§‘ --- Love bombing - Wikipedia (2025_9_21 18ï¼š06ï¼š27).html"
    ]
    
    # æ¦‚å¿µåç§°æ˜ å°„
    concept_names = {
        "DARVO": "DARVO",
        "ä¹ å¾—æ€§å¤±åŠ©": "ä¹ å¾—æ€§å¤±åŠ© (Learned Helplessness)",
        "åˆ›ä¼¤æ€§ç»“åˆ": "åˆ›ä¼¤æ€§ç»“åˆ (Traumatic Bonding)", 
        "ç…¤æ°”ç¯æ•ˆåº”": "ç…¤æ°”ç¯æ•ˆåº” (Gaslighting)",
        "çˆ±æƒ…è½°ç‚¸": "çˆ±æƒ…è½°ç‚¸ (Love Bombing)"
    }
    
    all_chinese_content = []
    all_chinese_content.append("=" * 80)
    all_chinese_content.append("å¿ƒç†å­¦æ¦‚å¿µä¸­æ–‡å†…å®¹æå–ç»“æœ")
    all_chinese_content.append("=" * 80)
    all_chinese_content.append(f"æå–æ—¶é—´: {os.popen('date').read().strip()}")
    all_chinese_content.append(f"æ€»æ–‡ä»¶æ•°: {len(html_files)}")
    all_chinese_content.append("=" * 80)
    all_chinese_content.append("")
    
    extracted_count = 0
    
    for html_file in html_files:
        if not os.path.exists(html_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {html_file}")
            continue
            
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {os.path.basename(html_file)}")
        
        # ç¡®å®šæ¦‚å¿µåç§°
        concept_name = "æœªçŸ¥æ¦‚å¿µ"
        for key, value in concept_names.items():
            if key in html_file:
                concept_name = value
                break
        
        chinese_texts = extract_html_chinese_content(html_file)
        
        if chinese_texts:
            all_chinese_content.append("=" * 60)
            all_chinese_content.append(f"ğŸ“š {concept_name}")
            all_chinese_content.append("=" * 60)
            all_chinese_content.append(f"æ–‡ä»¶: {os.path.basename(html_file)}")
            all_chinese_content.append(f"æå–æ¡ç›®æ•°: {len(chinese_texts)}")
            all_chinese_content.append("-" * 40)
            all_chinese_content.append("")
            
            for i, text in enumerate(chinese_texts, 1):
                all_chinese_content.append(f"{i:03d}. {text}")
                all_chinese_content.append("")
            
            extracted_count += 1
            print(f"âœ… æˆåŠŸæå– {len(chinese_texts)} æ¡ä¸­æ–‡å†…å®¹")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å†…å®¹")
    
    # å†™å…¥æ–‡ä»¶
    output_file = "psychology_concepts_chinese_content.txt"
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_chinese_content))
        
        print(f"\nğŸ‰ æå–å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸ“Š æˆåŠŸå¤„ç†: {extracted_count}/{len(html_files)} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“„ æ€»å†…å®¹è¡Œæ•°: {len(all_chinese_content)}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        file_size = os.path.getsize(output_file)
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024:.1f} KB)")
        
    except Exception as e:
        print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    main()